{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yuliya Akchurina \n",
    "# CISC6210 Natural Language Processing\n",
    "# Fall 2021\n",
    "# Homework_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1. \n",
    "# Read poems from .txt files in local folder into a table which has five columns - Author, Title, Tags, Body, Link. \n",
    "# Each poem is a row of the table.\n",
    "# Save the table into a local Microsoft Excel Worksheet named CleanOutputLoveOutput.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import re \n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder Path\n",
    "folder_path = \"C:\\\\Users\\\\Yuliya.DESKTOP-FMS37R3\\\\Documents\\\\Fordham Fall 2021 Classes\\\\CISC6210 NLP\\\\LoveOutput\\\\\"\n",
    "\n",
    "# Change the directory\n",
    "os.chdir(folder_path)\n",
    "\n",
    "# get file names into a list\n",
    "filenames = [i for i in glob.glob(\"*.txt\")]\n",
    "#print(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2232\n"
     ]
    }
   ],
   "source": [
    "#check how many files we have\n",
    "print(len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yuliya.DESKTOP-FMS37R3\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#Load all poems to create list of dataframes\n",
    "\n",
    "df = [pd.read_csv(file, sep = \"\\n\\n\", header=None) for file in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2232\n"
     ]
    }
   ],
   "source": [
    "#check size\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transpose each dataframe in the list and concatenate the transposed dataframes into a single dataframe\n",
    "for i in range(0,len(df)):\n",
    "    df[i] = df[i].T\n",
    "    \n",
    "poem_data = pd.concat(df)                   \n",
    "poem_data = poem_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns\n",
    "poem_data = poem_data.rename(columns={0: \"Title_Author\", 1: \"Tags\", 2: \"Body\", 3: \"Link\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Title_Author                                               Tags  \\\n",
      "0    1979 By Roddy Lumsden  Living ;Life Choices ;Time & Brevity ;Love ;De...   \n",
      "1  66 By Suzanne Gardinier            Living ;Love ;Relationships ;Free Verse   \n",
      "\n",
      "                                                Body  \\\n",
      "0  They arrived at the desk of the Hotel Duncan<b...   \n",
      "1  I'm used to the emperor's bitterness<br> I can...   \n",
      "\n",
      "                                                Link  \n",
      "0  original link: https://www.poetryfoundation.or...  \n",
      "1  original link: https://www.poetryfoundation.or...  \n"
     ]
    }
   ],
   "source": [
    "#confirm the columns were renamed\n",
    "print(poem_data[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove \"original link: \" from Link column\n",
    "poem_data['Link'] = poem_data['Link'].str.replace('original link: ', '', regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#strip whitespace \n",
    "#poem_data['Link'] = poem_data['Link'].str.strip()\n",
    "#poem_data['Link'] = poem_data['Link'].str.rstrip()  #remove trailing space\n",
    "#poem_data['Link'] = poem_data['Link'].str.replace(\" \", \"\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confrim\n",
    "#print(poem_data[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split title and author into two columns\n",
    "poem_data[\"Title_Author\"] = poem_data[\"Title_Author\"].str.replace(' By ', '_', regex=True)\n",
    "poem_data[[\"Title\", \"Author\"]] = poem_data[\"Title_Author\"].str.rsplit(\"_\", 1, expand=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rearrange columns in dataframe \n",
    "poem_data = poem_data[['Author', 'Title', 'Tags','Body','Link','Title_Author']]\n",
    "\n",
    "# Drop last column of a dataframe\n",
    "poem_data = poem_data.iloc[: , :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace with line breaks replaced by [L] and paragraph breaks replaced by [P]\n",
    "\n",
    "poem_data['Body'] = poem_data['Body'].str.replace('<br>', '[L]', regex=False)\n",
    "poem_data['Body'] = poem_data['Body'].str.replace('<br><br>', '[P]', regex=False)\n",
    "poem_data['Body'] = poem_data['Body'].str.replace('<p>', '[P]', regex=False)\n",
    "poem_data['Body'] = poem_data['Body'].str.replace('</p>', '[P]', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#strip remaining HTML tags \n",
    "\n",
    "poem_data['Body'] = poem_data['Body'].str.replace(r'<[^<>]*>', '', regex=True)\n",
    "poem_data['Title'] = poem_data['Title'].str.replace(r'<[^<>]*>', '', regex=True)\n",
    "\n",
    "poem_data['Author'] = poem_data['Author'].str.replace(r'[&#039;]', '', regex=True)\n",
    "poem_data['Title'] = poem_data['Title'].str.replace(r'[&#039;]', '', regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Title</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Body</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2228</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2229</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2230</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2231</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2232 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Author  Title   Tags   Body   Link\n",
       "0      False  False  False  False  False\n",
       "1      False  False  False  False  False\n",
       "2      False  False  False  False  False\n",
       "3      False  False  False  False  False\n",
       "4      False  False  False  False  False\n",
       "...      ...    ...    ...    ...    ...\n",
       "2227   False  False  False  False  False\n",
       "2228   False  False  False  False  False\n",
       "2229   False  False  False  False  False\n",
       "2230   False  False  False  False  False\n",
       "2231   False  False  False  False  False\n",
       "\n",
       "[2232 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# identify missing values in the dataframe\n",
    "# if the missing values anything but a link remove rows containing missing values\n",
    "poem_data.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Title</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Body</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2232</td>\n",
       "      <td>2232</td>\n",
       "      <td>2232</td>\n",
       "      <td>2040</td>\n",
       "      <td>2040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1041</td>\n",
       "      <td>2183</td>\n",
       "      <td>1860</td>\n",
       "      <td>2037</td>\n",
       "      <td>2040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>William Shakespeare</td>\n",
       "      <td>Song</td>\n",
       "      <td>Love ;Realistic &amp; Complicated</td>\n",
       "      <td>By                                            ...</td>\n",
       "      <td>https://www.poetryfoundation.org/poems/50338/w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>52</td>\n",
       "      <td>11</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Author Title                           Tags  \\\n",
       "count                  2232  2232                           2232   \n",
       "unique                 1041  2183                           1860   \n",
       "top     William Shakespeare  Song  Love ;Realistic & Complicated   \n",
       "freq                     52    11                             35   \n",
       "\n",
       "                                                     Body  \\\n",
       "count                                                2040   \n",
       "unique                                               2037   \n",
       "top     By                                            ...   \n",
       "freq                                                    3   \n",
       "\n",
       "                                                     Link  \n",
       "count                                                2040  \n",
       "unique                                               2040  \n",
       "top     https://www.poetryfoundation.org/poems/50338/w...  \n",
       "freq                                                    1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poem_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Author      0\n",
       "Title       0\n",
       "Tags        0\n",
       "Body      192\n",
       "Link      192\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify how many values are missing in each column\n",
    "poem_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows if values are missing in any column but \"Link\" since link is optional \n",
    "poem_data = poem_data.dropna(axis=0, how='any', subset=['Author', 'Title', 'Tags', 'Body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2040, 5)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check new size (2040, 5)\n",
    "poem_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Author    0\n",
       "Title     0\n",
       "Tags      0\n",
       "Body      0\n",
       "Link      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify how many values are missing in each column left\n",
    "poem_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save locally to excel. \n",
    "poem_data.to_excel(r\"C:\\Users\\Yuliya.DESKTOP-FMS37R3\\Documents\\Fordham Fall 2021 Classes\\CISC6210 NLP\\Homework\\CleanOutputLoveOutput.xlsx\",\n",
    "                index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once you processed all poems, show information of the table on screen, such as total number of poems stored, \n",
    "# total number of authors, sort authors by the amount of their poems collected in the table, \n",
    "# and show top 20 authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_poem = len(poem_data[\"Title\"])\n",
    "num_author = len(poem_data[\"Author\"])\n",
    "\n",
    "# get top 20 most frequent authors\n",
    "n = 20\n",
    "top20 = poem_data['Author'].value_counts()[:n].index.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#poem_data['Author'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "Total number of poems stored: 2040\n",
      "Total number of authors: 2040\n",
      "The top 20 Authors are:\n",
      " Number 1 is William Shakespeare has 52 poems\n",
      " Number 2 is John Donne has 28 poems\n",
      " Number 3 is Edmund Spenser has 23 poems\n",
      " Number 4 is Sir  Thomas Wyatt has 19 poems\n",
      " Number 5 is Robert Browning has 19 poems\n",
      " Number 6 is Anonymous has 19 poems\n",
      " Number 7 is John Keats has 17 poems\n",
      " Number 8 is Algernon Charles Swinburne has 15 poems\n",
      " Number 9 is Thomas Campion has 15 poems\n",
      " Number 10 is Robert Burns has 13 poems\n",
      " Number 11 is George Meredith has 13 poems\n",
      " Number 12 is Alfred, Lord Tennyson has 13 poems\n",
      " Number 13 is William Butler Yeats has 13 poems\n",
      " Number 14 is Aphra Behn has 12 poems\n",
      " Number 15 is Andrew Marvell has 12 poems\n",
      " Number 16 is Christina Rossetti has 12 poems\n",
      " Number 17 is Brenda Shaughnessy has 12 poems\n",
      " Number 18 is Robert Herrick has 11 poems\n",
      " Number 19 is Amy Lowell has 11 poems\n",
      " Number 20 is Walt Whitman has 11 poems\n"
     ]
    }
   ],
   "source": [
    "print(\"Summary:\")\n",
    "print(f\"Total number of poems stored: {num_poem}\")\n",
    "print(f\"Total number of authors: {num_author}\")\n",
    "#print(f\"Top 20 Authors are: {top20}\")\n",
    "\n",
    "print(\"The top 20 Authors are:\")\n",
    "for i in range(0,20):\n",
    "    print(f\" Number {i+1} is {top20[i]} has {(poem_data['Author'].value_counts()[i])} poems\")\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2_1. \n",
    "# Read data from CleanOutputLoveOutput.xlsx, collect information about words,sentences, paragraphs, \n",
    "# and punctuations of poems in this data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read excel file CleanOutputLoveOutput.xlsx into df\n",
    "file_path = \"C:\\\\Users\\\\Yuliya.DESKTOP-FMS37R3\\\\Documents\\\\Fordham Fall 2021 Classes\\\\CISC6210 NLP\\\\Homework\\\\CleanOutputLoveOutput.xlsx\"\n",
    "CleanOut_df = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new table\n",
    "column_names = [\"PoemID\", \"Author\", \"LengthOne\", \"LengthTwo\", \"NumLine\", \"NumPara\", \"NumSent\", \"NumComma\"]\n",
    "stat_df = pd.DataFrame(columns = column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add author names to new df\n",
    "stat_df[\"Author\"] = CleanOut_df[\"Author\"].copy()\n",
    "\n",
    "#populate col PoemID as row index of each poem from CleanOutputLoveOutput.xlsx file \n",
    "stat_df[\"PoemID\"]= CleanOut_df[\"Author\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yuliya.DESKTOP-FMS37R3\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "#LengthOne: the total number of tokens in this poem, punctuation marks are not included.\n",
    "for i in range(0, len(CleanOut_df)):\n",
    "    num_token = 0\n",
    "    num_token = CleanOut_df[\"Body\"][i].split()\n",
    "    stat_df[\"LengthOne\"][i] = int(len(num_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yuliya.DESKTOP-FMS37R3\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# LengthTwo: the total number of tokens in this poem, punctuation marks are included.\n",
    "for i in range(0, len(CleanOut_df)):    \n",
    "    num_tokenize = 0  \n",
    "    num_tokenize = nltk.word_tokenize(CleanOut_df[\"Body\"][i])\n",
    "    stat_df[\"LengthTwo\"][i] = int(len(num_tokenize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yuliya.DESKTOP-FMS37R3\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\Yuliya.DESKTOP-FMS37R3\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\Yuliya.DESKTOP-FMS37R3\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(CleanOut_df)):\n",
    "    \n",
    "    #NumLine: line breaks plus paragraph breaks\n",
    "    stat_df[\"NumLine\"][i] = CleanOut_df[\"Body\"][i].count(\"[L]\") + CleanOut_df[\"Body\"][i].count(\"[P]\")\n",
    "    #NumPara: paragraph breaks\n",
    "    stat_df[\"NumPara\"][i] = CleanOut_df[\"Body\"][i].count(\"[P]\")\n",
    "    #NumComma: commas\n",
    "    stat_df[\"NumComma\"][i] = CleanOut_df[\"Body\"][i].count(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yuliya.DESKTOP-FMS37R3\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# NumSent: the total number of complete sentences (use nltk)\n",
    "# Remove [L] and [P] and replace with spaces before counting sentenses to get accurate results. \n",
    "# Otherwise line end [L] at the end are counted as a separate sentense. \n",
    "\n",
    "#sent_list = []\n",
    "\n",
    "CleanOut_df['Body'] = CleanOut_df['Body'].str.replace('[L]', ' ', regex=False)\n",
    "CleanOut_df['Body'] = CleanOut_df['Body'].str.replace('[P]', ' ', regex=False)\n",
    "\n",
    "for i in range(0, len(CleanOut_df)):\n",
    "\n",
    "    stat_df['NumSent'][i] = int(len(nltk.sent_tokenize(CleanOut_df['Body'][i])))\n",
    "    #sent_list.append(int(len(nltk.sent_tokenize(CleanOut_df['Body'][i]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(stat_df[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PoemID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2040.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1019.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>589.041594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>509.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1019.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1529.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2039.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            PoemID\n",
       "count  2040.000000\n",
       "mean   1019.500000\n",
       "std     589.041594\n",
       "min       0.000000\n",
       "25%     509.750000\n",
       "50%    1019.500000\n",
       "75%    1529.250000\n",
       "max    2039.000000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PoemID       2040\n",
       "Author       2040\n",
       "LengthOne    2040\n",
       "LengthTwo    2040\n",
       "NumLine      2040\n",
       "NumPara      2040\n",
       "NumSent      2040\n",
       "NumComma     2040\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PoemID                   0\n",
       "Author       A. E. Housman\n",
       "LengthOne               13\n",
       "LengthTwo               21\n",
       "NumLine                  0\n",
       "NumPara                  0\n",
       "NumSent                  1\n",
       "NumComma                 0\n",
       "dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_df.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PoemID          2039\n",
       "Author       sam sax\n",
       "LengthOne       5827\n",
       "LengthTwo       9247\n",
       "NumLine          971\n",
       "NumPara          147\n",
       "NumSent          427\n",
       "NumComma         663\n",
       "dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_df.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PoemID       1019.500000\n",
       "LengthOne     245.232843\n",
       "LengthTwo     421.606373\n",
       "NumLine        42.267157\n",
       "NumPara         0.424510\n",
       "NumSent        12.539216\n",
       "NumComma       20.706373\n",
       "dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PoemID       589.041594\n",
       "LengthOne    413.503223\n",
       "LengthTwo    675.345344\n",
       "NumLine       63.952500\n",
       "NumPara        3.613118\n",
       "NumSent       22.854068\n",
       "NumComma      40.448037\n",
       "dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2_2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create 3 new tables with 5 columns each\n",
    "column_names = [\"PoemID\", \"Author\", \"Body\", \"Length\", \"UniCount\"]\n",
    "\n",
    "table1_df = pd.DataFrame(columns = column_names)\n",
    "\n",
    "table2_df = pd.DataFrame(columns = column_names)\n",
    "\n",
    "table3_df = pd.DataFrame(columns = column_names)\n",
    "\n",
    "#add Author names to new df\n",
    "table1_df[\"Author\"] = CleanOut_df[\"Author\"].copy()\n",
    "table2_df[\"Author\"] = CleanOut_df[\"Author\"].copy()\n",
    "table3_df[\"Author\"] = CleanOut_df[\"Author\"].copy()\n",
    "\n",
    "#populate col PoemID as row index of each poem from CleanOutputLoveOutput.xlsx file \n",
    "table1_df[\"PoemID\"]= CleanOut_df[\"Author\"].index\n",
    "table2_df[\"PoemID\"]= CleanOut_df[\"Author\"].index\n",
    "table3_df[\"PoemID\"]= CleanOut_df[\"Author\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The total number of tokens in this poem, punctuation marks are included.\n",
    "table1_df[\"Body\"]= stat_df[\"LengthTwo\"].copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yuliya.DESKTOP-FMS37R3\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# populate the table 1 column \"Length\"\n",
    "for i in range(0, len(CleanOut_df)):\n",
    "    table1_df['Length'][i] = int(len(CleanOut_df['Body'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yuliya.DESKTOP-FMS37R3\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# populate the table 1 column \"UniCount\" with unique values of words in each poem vocabulary_size = len(set(text))\n",
    "for i in range(0, len(CleanOut_df)):\n",
    "    table1_df['UniCount'][i] = len(set(CleanOut_df['Body'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The second table is for tokenized words after stop words removal. (use nltk English stopwords list). \n",
    "# get stopwords \n",
    "#print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "\n",
    "# remove stopwords from Body column of every poem in df\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "for i in range(0, len(CleanOut_df)):\n",
    "     CleanOut_df[\"Body\"][i] = remove_stopwords(CleanOut_df[\"Body\"][i].lower())  #filtered \"Body\" column of poems with stopwords removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', \"'m\", 'emperor', \"'s\", 'bitter', 'ca', \"n't\", 'sweet', 'place', 'face', 'face', 'look', 'touch', 'oak', 'blossom', 'strip', 'swell', 'avenu', 'pavement', 'river', 'shirt', 'ca', \"n't\", 'night', 'gather', 'new', 'day', 'sweet', 'place', 'tomorrow', 'whisper', 'tonight', \"'s\", 'light', 'kiss', 'author', 'want', 'stop', 'you', \"'ll\", 'ruin', 'citi', 'woman', 'interrupt', 'sleep']\n"
     ]
    }
   ],
   "source": [
    "print(CleanOut_df[\"Body\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yuliya.DESKTOP-FMS37R3\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# populate the table 2 column \"Length\"\n",
    "for i in range(0, len(CleanOut_df)):\n",
    "    table2_df['Length'][i] = int(len(CleanOut_df['Body'][i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yuliya.DESKTOP-FMS37R3\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# populate the table 2 column \"Body\" - Tokenized words in poem the total number of tokens in this poem, punctuation marks are included.\n",
    "for i in range(0, len(CleanOut_df)):  \n",
    "    table2_df['Body'][i] = len(CleanOut_df[\"Body\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PoemID</th>\n",
       "      <th>Author</th>\n",
       "      <th>Body</th>\n",
       "      <th>Length</th>\n",
       "      <th>UniCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Roddy Lumsden</td>\n",
       "      <td>177</td>\n",
       "      <td>899</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Suzanne Gardinier</td>\n",
       "      <td>45</td>\n",
       "      <td>272</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Jeff Daniel Marion</td>\n",
       "      <td>60</td>\n",
       "      <td>338</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PoemID              Author Body Length UniCount\n",
       "0       0       Roddy Lumsden  177    899       34\n",
       "1       1   Suzanne Gardinier   45    272       25\n",
       "2       2  Jeff Daniel Marion   60    338       30"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table2_df[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yuliya.DESKTOP-FMS37R3\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# populate the table 2 column \"UniCount\" with the vocabulary size - number of unique words used in each poem \n",
    "for i in range(0, len(CleanOut_df)):\n",
    "    table2_df['UniCount'][i] = len(set(CleanOut_df['Body'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The third table is for tokenized words after stop words removal and stemming. (use one stemmer - porter’s from nltk)\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "#porter = nltk.PorterStemmer()\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "for i in range(0, len(CleanOut_df)):\n",
    "     CleanOut_df[\"Body\"][i] = word_tokenize(CleanOut_df[\"Body\"][i])\n",
    "        \n",
    "#function for stemming \n",
    "def stemming(text):\n",
    "    porter = PorterStemmer()\n",
    "    \n",
    "    result=[]\n",
    "    for word in text:\n",
    "        result.append(porter.stem(word))\n",
    "    return result        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appluy stemming to the poems \n",
    "CleanOut_df['Body']=CleanOut_df['Body'].apply(stemming)\n",
    "#CleanOut_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yuliya.DESKTOP-FMS37R3\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# populae Body of table 3 \n",
    "for i in range(0, len(CleanOut_df)):\n",
    "    table3_df[\"Body\"][i] = int(len(CleanOut_df[\"Body\"][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yuliya.DESKTOP-FMS37R3\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# populae Length of table 3 \n",
    "for i in range(0, len(CleanOut_df)):\n",
    "    table3_df['Length'][i] = sum([len(element) for element in CleanOut_df['Body'][i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       687\n",
      "1       205\n",
      "2       255\n",
      "3        51\n",
      "4       809\n",
      "       ... \n",
      "2035    478\n",
      "2036    574\n",
      "2037    329\n",
      "2038    511\n",
      "2039    441\n",
      "Name: Length, Length: 2040, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(table3_df['Length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PoemID              Author Body Length UniCount\n",
      "0       0       Roddy Lumsden  177    687      131\n",
      "1       1   Suzanne Gardinier   45    205       39\n",
      "2       2  Jeff Daniel Marion   60    255       48\n"
     ]
    }
   ],
   "source": [
    "print(table3_df[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yuliya.DESKTOP-FMS37R3\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# populate the table 3 column \"UniCount\" with the vocabulary size - number of unique words used in each poem \n",
    "for i in range(0, len(CleanOut_df)):\n",
    "    table3_df['UniCount'][i] = len(set(CleanOut_df['Body'][i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# SAVE all 4 tables to the same excel file ################\n",
    "\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "path = \"C:\\\\Users\\\\Yuliya.DESKTOP-FMS37R3\\\\Documents\\\\Fordham Fall 2021 Classes\\\\CISC6210 NLP\\\\Homework\\\\ProcessedLoveOutput.xlsx\"\n",
    "\n",
    "with pd.ExcelWriter(path, engine='xlsxwriter') as writer:    \n",
    "    stat_df.to_excel(writer, 'Statistics')   \n",
    "    table1_df.to_excel(writer, 'Table1')  \n",
    "    table2_df.to_excel(writer, 'Table2') \n",
    "    table3_df.to_excel(writer, 'Table3') \n",
    "    \n",
    "    writer.save()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
